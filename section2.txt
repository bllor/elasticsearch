Section2
-------------------------------
분석기

매핑이란?
스키마와 같다 == 데이터를 어떤 형식으로 저장할 것인지 어떻게 색인화하고 분석할 것인지를 알려주는 것

Put 스키마를 저장하는 것

Curl -XPUT 127.0.0.1:9200/movies -d'
{
	"mappings":{
		"properties":{
			"year":{"type": "date"}
			}
		}
}'

http에 put명령(인덱스 생성)을 보내며, 인덱스 이름은 movies,
매핑할 json데이터는 year이며, 타입은 date로 한다.

매핑의 종류
1.field types
String, byte, integer etc

2.field index

Analyzed : 필드 인덱스가 전문검색(full-text search)을 하길 원할 경우 사용
not_analyzed : 해당 정보를 전체 텍스트 검색의 대상으로 포함하지 않는다.
no

3.field analyzer
[1]Tokenizer : 공백이나 구두점 또는 특수 문자를 기준으로 문자열을 분할할 방법을 지정하는 것
공백, 문자가 아닌 것으로 분석

[2]Token filter : 모든 문자를 소문자화 시키거나 어간, 동의어 등의 작업을 진행
소문자, 동의어 등으로 구분 the, in과 같은 불용어로도 구분할 수 있다.


[3]character filter : HTML 인코딩 제거 등등


-------------------------------
Json/ rest를 통해 단일 동영상 가져오기
Tips : ctrl+v+tap를 누르면 탭키처럼 띄워짐


_Search?pretty
 인덱스를 찾는 명령이고,
pretty는 탭과 줄바꿈을 사용해 결과를 읽기 좋은 형식으로 표시

get은 정보를 검색할 경우 사용, post는 인덱스에 새 문서를 추가할 때 사용
put은 자료를 저장할 때 사용한다.

curl -XGET 127.0.0.1:9200/인덱스명/사용할 함수
인덱스에서 해당함수를 사용한다.
curl -XGET 127.0.0.1:9200/movies/_search
검색을 실시한다.

-------------------------------
Bulk API로 한 번에 여러 동영상 삽입하기

문서를 생성할 때는 create로 생성한다.
{create}
{설명}
이런 식으로 대용량 데이터를 사용하는 이유는 문서에 따라 샤드가 나눠지기 때문에,
대용량으로 자료를 넣을 경우 따로따로 넣어주어야 한다.

bulk파일을 넣을 경우,
주소/_bulk?pretty --data-binary 파일명을 이용하여
파일에 있는 내용을 추가할 수 있다.

bulk 데이터를 다운받는 스크립트를 짜서 넣을 수 있다.

-------------------------------
데이터 업데이트

인덱스화된 문서의 내용을 변경 또는 업데이트 하는 방법

일단 작성된 문서를 변경할 수 없지만 기존 문서를 복사하여 변경된 내용을 저장한 새로운 문서가 생긴다.
문서를 지울 수 없지만 version을 통해서 새로 업데이트가 된 것을 찾을 수 있다.

주소/색인/_doc/index번호/_update -d '{내용}'을 통해서 업데이트할 수 있다.
업데이트를 하게되면 해당 문서의 properties중에 version번호가 변경된다.


-------------------------------
데이터 삭제
-XDELETE 주소/인덱스명/_doc/index number

데이터를 찾은 후, 인덱스 번호를 찾아서 삭제하면된다.

데이터를 찾는 방법
get 주소/인덱스명/_search?q=데이터

Ex) get 주소/인덱스명/_search?q=Dark
Dark가 포함된 문서를 찾아준다.



-------------------------------
동영상 삽입, 업데이트 및 삭제

삽입
Xput 주소/인덱스명/_doc/인덱스 번호?pretty -d '{}'

업데이트
xPost 주소/인덱스명/_doc/인덱스 번호/_update -d'
"doc" : {변경할 내용}
'

찾기 
Xget 주소/인덱스명/_search?q="찾는 자료명"

지우기
Curl -xdelete 주소/인덱스명/_doc/인덱스번호


-------------------------------
동시성 처리

Optimistic concurrency control - 동시성 이슈를 해결하는 방법
여러 사용자가 하나의 문서를 업데이트 하려고 하면 충돌이 발생할 수 있는데,
seq_no를 통해서 순서를 부여하고, 같은 번호를 가진 사용자 중 나중에 업데이트를 한 사용자의
내용은 에러가 나면서 반영되지 않는다.
에러 발생 시, retry_on_conflict변수를 통해 재시도할 수 있도록 도와준다.
충돌이 발생하게 되면 재시도 할 수 있도록 도와준다.
Error : retry_on_conflicts가 출동이 났다는 에러인데,
이 에러가 발생할 경우 재시도한다.

Xput 주소/인덱스명/_doc/인덱스번호?if_seq_no=X&if_primary_term=Y
seq_no =x, primary_term=Y일 경우 업데이트할 수 있게 하는 명령어

seq_no의 번호가 바뀔 것을 감안하여,
-xPost 주소/인덱스/_doc/인덱스번호/_update=?retry_on_conflict=5 -d " " 명령어를 사용
Retry_on_conflict = 5 <- 동시성 이슈가 발생할 경우, 새로운 번호로 최대 5번까지 자동으로 다시 시도



-------------------------------
분석기 및 토크나이저 사용
텍스트를 정확히 매핑하려면 인덱스를 키워드 유형을 사용한다.
키워드 매핑을 사용하면 정확히 일치 했을 때 해당 정보를 가져오고,
텍스트 유형 매치를 하게 되면 부분 일치 시 정보를 가져온다.

텍스트 타입을 사용할 경우, 대소문자 구분을 하지 않게 만들 수 있고, 불용어를 제거할 수 있다.

-xget 주소/인덱스명/_search?pretty -d '
{
query:{
function : {
}
}
}
사용되는 function에 따라 조회되는 값들이 다르다.
match를 사용할 경우 match 안의 내용이 포함된 데이터들을 가져오고,
match_phrase를 사용할 경우 안의 내용이 포함된 데이터들을 가져오는데,
sci-fi로 되어있고, sci를 match_phrase로 사용하면 sci-fi를 가져온다.
sci를 따로 인지하기 때문이다.





-xget 주소/인덱스명/_search?pretty -d '
{
"query" :{
"Match_phrase" : { 내용
}
}
}
'
Match_phrase의 내용을 대소문자 구분없이 가져온다.


대소문자를 구분하고, 해당 내용에 해당하는 자료만 가져오고 싶은 경우,
인덱스 생성시 원하는 부분의 type을 keyword로 설정하면 된다.
Ex) 영화 장르에서 "sci-fi"와 일치하는 것만 가져오고 싶은 경우
-xput address/index_name -d '
{ 
"mappings": {
"properties" :{
"id" : {"type": "integer"},
"genre" : {"type": "keyword"}
		}
	}
}
'
와 같은 형식으로 만들 경우, genre는 keyword 형식이 되고, 정확히 일치할 경우만 가져온다.




-------------------------------
데이터 모델링 및 부모 관계

데이터 정규화
저장 공간을 줄이고, 쉽게 변경할 수 있지만,
쿼리를 두번 사용해야하고, 저장공간이 매우 저렴하다.
컴퓨터 클러스터의 성능이 많이 증가해서, 저장공간 걱정은 x

정규화를 할 때 고려할 것 
이러한 요청을 할 때 클러스터의 트래픽을 2배 늘릴 수 있냐는 것
두 번의 요청이 아닌 한 번의 접근으로 원하는 정보를 같는 것이 더 좋은 것 같다.

비정규화 데이터
하나의 쿼리로 원하는 정보를 조회 가능


부모 관계 설정
-xput address/indexName -d '

{
"mappings": {
"properties": {
"film_to_franchise": {
"type": "join",
"relation": {"franchise": "film"} //부모가 프랜차이즈, 자식이 film
}
}
}
}
' 
첫번째 인덱스내용에 franchise를, 그 다음에는 film에 배정한다.

-xput address/indexName/_search?pretty -d '
{
has_parent : {
"Type" : "frnanchise"
}
}
'

has_parent를 통해 부모의 자식들을 알 수 있고,
-xput address/indexName/_search?pretty -d '
{
has_chile : {
"type" : "film"
}
}
'
has_child를 통해 자식의 부모를 알 수 있다.


-------------------------------
플랫 데이터 유형
내부 필드의 내용이 많을 경우 성능이 감소한다.
-> why ? 다양한 매핑 타입들이 생성되므로

클러스터는 노드의 모음
노드가 여러 개 있으면 색인 및 검색 작업을 보다 효율적으로 수행할 수 있다.
클러스터 상태가 노드에 전달되어 엘라스틱서치가 정상작동
이 클러스터 내에는 다른 노드에 최신 크러스터 상태를 전송하는 마스터 노드가 있다.
클러스터 상태를 수신하면, 각 노드는 마스터 노드에 수신 완료 신호를 보낸다.
매핑이 새로되면 클러스터 상태 변경
클러스터가 업데이트 되지 않으면 성능 저하 및 멈출 수 있다.
매핑 폭발을 막기 위해 플랫 데이터를 도입

플랫 데이터
전체 개체와 내부 필드를 단일 필드로 매핑
필드에 내부 필드가 포함된 경우 플랫 데이터 유형은 상위 필드를 필랫이라는 단일 유형으로 매핑하고
내부 필드는 매핑에 표시하지 않음으로 전체 맵 필드 크기가 줄어든다.
플랫 데이터로 만드려면,
인덱스 생성시 properties에서 type을 flattened로 설정한다.
플랫 데이터 유형 사용시 주의점
-플랫 데이터 유형개체의 필드가 keyword로 처리된다.
-결과 강조 표시 기능이 해당 필드에 활성화되지 않는다


*
내부의 내용을 검색하고 싶을 때
Host 내에 version이 있는데 version으로 검색하고 싶으면
"Query":{
"Match": { 
"Host.version" : "검색명"
}
}
와 같은 형식으로 검색

-----------------------------
매핑 예외처리
매핑이 되는 경우
json이 인덱스화 될 때
프로세스 과정에서 발생하는 중재 데이터의 구조

명시적 매핑에서 필드가 일치하지 않을 때
동적 매핑에서 필드의 수가 너무 많이 증가될 때 발생한다.

매핑에 예외처를 할 때는 해당 인덱스를 닫은 후 
curl --location --request PUT ADDRESS/INDEX_NAME/_settings ' --data-raw '{
"index.mapping,ignore_malformed": true
}'
명령어를 실행하면 예외상황이라도 매핑한다.
이렇게 되면 json데이터를 매핑하지 못한다.
이러한 문제는 logstash를 사용하거나 다른 방법을 사용해야한다.


""안의 숫자도 정수로 인지한다.
















